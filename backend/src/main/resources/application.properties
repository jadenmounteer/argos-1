# Server 
server.port=8080

# Virtual Threads (Directive 03: I/O-bound operations)
spring.threads.virtual.enabled=true

# Ollama (local LLM â€” base URL and model required by LangChain4j)
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=deepseek-r1:8b
